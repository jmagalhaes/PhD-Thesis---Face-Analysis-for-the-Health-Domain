%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% abstrac-en.tex
%% UNL thesis document file
%%
%% Abstract in English
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Communication is a crucial part of our daily lives. Through communication we exchange ideas, opinions, feelings, and much more.
However, neurological disorders or traumatic brain injuries can affect speech production through abnormalities in speech motor control.
Besides causing difficulties in speech production, neurological disorders can also cause difficulty in expressing emotions. Patients with
Parkinson’s disease (PD), e.g., develop difficulties in speech production and in maintaining voice quality, but also in emotional facial
expressiveness.
Even though the expression of emotions is not directly affected by an existing neurological problem, speech disabilities can cause an
frustration and reduced self-esteem which on the other hand can enhance symptoms of speech disorders. This is the case, for instance,
in stuttering.

To understand the relationship between motor speech disorders and expressed emotions, the goal of this Phd thesis is to collect data of patients having Dysarthria, Apraxia of speech or Stuttering. As communication by itself is multimodal, the data will be collected using different modalities to gather video, audio and physiological data.
The data collected will be labeled by Speech Language Pathologists (SLPs) and analyzed using hand-crafted features. The data of the
different modalities will be analyzed separately using different types of classification (binary, multi-class, multi-label), as well as fused
together in order to evaluate if the different modalities bring more insights if they are joined in the feature space prior to classification.

By understanding the relationship between the severity of motor speech disorders and the expressed emotions of an individual, the
hope is to provide caregivers insights of the inner emotional state of the patient which otherwise would be difficult to perceive, and to
provide patients with biofeedback, such that they can adapt their emotional state to one that supports speech production instead of
sabotaging it.


% Palavras-chave do resumo em Inglês
\begin{keywords}
facial expressions, motor speech disorders, stuttering, dysarthria, apraxia of speech, emotion detection, EDA, multimodal machine learning 
\end{keywords} 



%=================
\begin{comment}
The abstract should not exceed one page and should answer the following questions:

\begin{itemize}
	\item What's the problem?
	\item Why is it interesting?
	\item What's the solution?
	\item What follows from the solution?
\end{itemize}
\end{comment}